{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Sum on all episodes 0.2178\n",
      "Final Values Q-Table\n",
      "[[2.19895425e-03 1.88201146e-03 2.01879365e-03 5.10393463e-03]\n",
      " [1.81824452e-03 1.17416216e-03 9.15800901e-03 1.98907839e-03]\n",
      " [1.27055134e-03 2.38970359e-03 1.24191135e-02 1.83215839e-03]\n",
      " [2.16046264e-03 1.92698333e-03 9.91172445e-03 1.90614740e-03]\n",
      " [1.18475853e-03 2.42943286e-03 1.62810902e-02 1.79487564e-03]\n",
      " [2.15138259e-03 0.00000000e+00 2.64022630e-02 2.04807179e-03]\n",
      " [0.00000000e+00 0.00000000e+00 5.20709014e-02 0.00000000e+00]\n",
      " [2.20166211e-03 4.33670918e-02 2.91974594e-03 0.00000000e+00]\n",
      " [1.77939680e-03 3.21493839e-03 1.80546561e-03 1.81083957e-03]\n",
      " [1.44275129e-03 1.97532658e-03 1.47687487e-03 5.61497639e-03]\n",
      " [1.48624970e-03 1.76855421e-03 1.14443769e-03 1.13802644e-02]\n",
      " [3.07038435e-04 7.08551857e-04 1.98435188e-04 1.07353942e-02]\n",
      " [2.60126751e-03 9.95657990e-04 1.94746248e-03 2.59562397e-02]\n",
      " [1.97606799e-03 1.73512448e-03 2.82596950e-02 3.29792562e-03]\n",
      " [3.33239093e-03 6.59579722e-02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 8.08622030e-02 2.26514572e-03 0.00000000e+00]\n",
      " [9.13928811e-04 1.61797901e-03 1.80495362e-03 1.86753707e-03]\n",
      " [9.04343709e-04 1.36788276e-03 5.47874892e-03 1.78957670e-03]\n",
      " [2.91495829e-03 4.49419542e-04 1.52947175e-04 3.06089102e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.66146488e-05 2.10331720e-04 6.32994241e-03 3.18135142e-04]\n",
      " [4.95460537e-05 4.40871160e-04 4.29011234e-04 6.00291116e-02]\n",
      " [2.47863110e-03 0.00000000e+00 1.42771850e-01 1.53186739e-03]\n",
      " [0.00000000e+00 1.72466846e-01 0.00000000e+00 0.00000000e+00]\n",
      " [1.29440657e-03 9.06440634e-04 1.84165052e-03 1.76213904e-03]\n",
      " [7.78528243e-04 7.45462995e-04 4.79936231e-04 2.16523322e-03]\n",
      " [6.79016219e-04 4.64388758e-04 2.93178980e-04 2.13856414e-03]\n",
      " [1.59205539e-04 6.36111711e-04 4.48266892e-05 5.62860581e-05]\n",
      " [1.48685927e-03 1.35607592e-04 1.70276159e-04 3.03171037e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.47341639e-03 1.10620148e-01 0.00000000e+00]\n",
      " [0.00000000e+00 1.97342041e-01 0.00000000e+00 0.00000000e+00]\n",
      " [9.18908833e-04 5.18289813e-04 6.00611406e-04 1.26514988e-03]\n",
      " [2.58424363e-05 6.02118981e-04 5.46469652e-04 1.57401289e-03]\n",
      " [1.57804292e-03 1.89129818e-04 2.57298538e-04 1.00864841e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.69342803e-04 4.93161394e-05 3.85198607e-03 9.77498959e-05]\n",
      " [6.08758707e-04 5.45434298e-03 6.27856968e-04 8.85630984e-04]\n",
      " [8.71282866e-04 0.00000000e+00 1.80922416e-03 5.32641840e-02]\n",
      " [0.00000000e+00 1.75599755e-01 0.00000000e+00 0.00000000e+00]\n",
      " [7.57103982e-04 3.20927357e-04 2.29549226e-04 5.29523986e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.77227761e-05 1.47290076e-04 5.14290000e-05 2.26050123e-04]\n",
      " [7.27850457e-05 1.04503269e-04 2.40830388e-03 2.16790582e-04]\n",
      " [5.74484717e-03 2.92892287e-04 3.14401128e-04 2.33405738e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.07182851e-04 2.51948928e-01 1.17099747e-04]\n",
      " [3.88429185e-04 6.44141693e-05 1.29903193e-04 5.29989449e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.97833188e-05 1.36511644e-04 1.86094014e-04 6.58066446e-06]\n",
      " [5.97663297e-05 3.52119364e-05 9.04057639e-06 1.56424648e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.76032066e-03 2.31331783e-05 8.55827691e-05 3.47865952e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.80982152e-01 0.00000000e+00]\n",
      " [3.53015215e-04 1.70474423e-04 1.38567963e-04 9.18597900e-05]\n",
      " [0.00000000e+00 1.66135579e-04 1.14528660e-04 1.20432582e-04]\n",
      " [1.48851620e-04 0.00000000e+00 3.00403410e-06 1.31216110e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.32352524e-04 0.00000000e+00 6.18467647e-01 1.71078206e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 3.29764362e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np \n",
    "\n",
    "# 1. Load Environment and Q-table structure\n",
    "env = gym.make('FrozenLake8x8-v1')\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "# env.observation.n, env.action_space.n gives number of states and action in env loaded\n",
    "\n",
    "# 2. Parameters of Q-learning\n",
    "eta = .628\n",
    "gma = .9\n",
    "epis = 5000\n",
    "rev_list = [] # rewards per episode calculate\n",
    "\n",
    "# 3. Q-learning Algorithm\n",
    "for i in range(epis):\n",
    "    # Reset environment\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    #The Q-Table learning algorithm\n",
    "    while j < 99:\n",
    "#         env.render()\n",
    "        j+=1\n",
    "        # Choose action from Q table\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
    "        #Get new state & reward from environment\n",
    "        s1,r,d,_ = env.step(a)\n",
    "        #Update Q-Table with new knowledge\n",
    "        Q[s,a] = Q[s,a] + eta*(r + gma*np.max(Q[s1,:]) - Q[s,a])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "    rev_list.append(rAll)\n",
    "#     env.render()\n",
    "\n",
    "print(\"Reward Sum on all episodes \" + str(sum(rev_list)/epis))\n",
    "print(\"Final Values Q-Table\")\n",
    "print(Q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
